{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config, get_weights_file_path\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model, get_ds, greedy_decode\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# !pip install altair\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# !pip install jiwer gradio typing-extensions\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marianna\\Desktop\\Translation\\train.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordLevel\n",
      "File \u001b[1;32mc:\\Users\\Marianna\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.12.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(platform\u001b[38;5;241m.\u001b[39mpython_version()) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.7\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Marianna\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import Transformer\n",
    "from config import get_config, get_weights_file_path\n",
    "from train import get_model, get_ds, greedy_decode\n",
    "# !pip install altair\n",
    "# !pip install jiwer gradio typing-extensions\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentences: 767\n",
      "Max length of target sentences: 782\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_basename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(config, vocab_src\u001b[38;5;241m.\u001b[39mget_vocab_size(), vocab_tgt\u001b[38;5;241m.\u001b[39mget_vocab_size())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# load the pretrained weights\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[43mget_weights_file_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m29\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_filename)\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Marianna\\Desktop\\Translation\\config.py:34\u001b[0m, in \u001b[0;36mget_weights_file_path\u001b[1;34m(config, epoch)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weights_file_path\u001b[39m(config, epoch:\u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     33\u001b[0m     model_folder \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_folder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 34\u001b[0m     model_basename \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_basename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     35\u001b[0m     model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_basename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m/\u001b[39mmodel_folder\u001b[38;5;241m/\u001b[39mmodel_filename)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model_basename'"
     ]
    }
   ],
   "source": [
    "# we load the model\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, vocab_src, vocab_tgt = get_ds(config)\n",
    "model = get_model(config, vocab_src.get_vocab_size(), vocab_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# load the pretrained weights\n",
    "model_filename = get_weights_file_path(config, f\"29\")\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function to load the batch\n",
    "def load_next_batch():\n",
    "    batch = next(iter(val_dataloader))\n",
    "    encoder_input = batch['encoder_input'].to(device)\n",
    "    encoder_mask = batch['encoder_mask'].to(device)\n",
    "    decoder_input = batch['decoder_input'].to(device)\n",
    "    decoder_mask = batch['decoder_mask'].to(device)\n",
    "\n",
    "    \n",
    "    # now we will convert the batch into tokens using the tokenizer\n",
    "    encoder_input_tokens = [vocab_src.id_to_token(idx) for idx in encoder_input[0].cpu().numpy()]\n",
    "    decoder_input_tokens = [vocab_tgt.id_to_token(idx) for idx in decoder_input[0].cpu().numpy()]\n",
    "\n",
    "    # lets infer using our greedy decoder\n",
    "    model_out = greedy_decode(model, encoder_input, encoder_mask,vocab_src,vocab_tgt,config['seq_len'], device)\n",
    "\n",
    "    return batch,encoder_input_tokens, decoder_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will build the functions for visualize the attention\n",
    "def mtx2df(m, max_row, max_col,row_tokens, col_tokens):\n",
    "    return pd.DataFrame(\n",
    "        [\n",
    "            (\n",
    "                r,\n",
    "                c,\n",
    "                float(m[r,c]),\n",
    "                \"%.3d %s\" % (r, row_tokens[r] if len(row_tokens) > r else \"<blank>\"),\n",
    "                \"%.3d %s\" % (c, col_tokens[c] if len(col_tokens) > c else \"<blank>\"),\n",
    "\n",
    "            )\n",
    "            for r in range(m.shape[0])\n",
    "            for c in range(m.shape[1])\n",
    "            if r < max_row and c < max_col\n",
    "        ],\n",
    "        columns= [\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "    )\n",
    "\n",
    "def get_attn_map(attn_type: str, layer:int, head: int):\n",
    "    if attn_type ==\"encoder\":\n",
    "        attn = model.encoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"decoder\":\n",
    "        attn = model.decoder.layers[layer].self_attention_block.attention_scores\n",
    "    elif attn_type == \"encoder-decoder\":\n",
    "        attn = model.decoder.layers[layer].cross_attention_block.attention_scores\n",
    "        return attn[0, head].data\n",
    "\n",
    "def attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n",
    "    df = mtx2df(\n",
    "        get_attn_map(attn_type, layer, head),\n",
    "        max_sentence_len,\n",
    "        max_sentence_len,\n",
    "        row_tokens,\n",
    "        col_tokens,\n",
    "    )\n",
    "    return (\n",
    "        alt.Chart(data=df)\n",
    "        .mark_rect()\n",
    "        .encoder(\n",
    "            x = alt.X(\"col_tokens\", axis= alt.Axis(title=\"\")),\n",
    "            y = alt.Y(\"row_token\", axis = alt.Axis(title=\"\")),\n",
    "            color = \"value\",\n",
    "            tooltip = [\"row\", \"column\", \"value\", \"row_token\", \"col_token\"],\n",
    "        )\n",
    "        .properties(height=400, width=400, title=f\"Layer {layer} Head {head}\")\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "def get_all_attention_maps(attn_type: str, layers:list[int], heads:list[int], row_tokens:list, col_tokens, max_sentence_len:int):\n",
    "    charts = []\n",
    "    for layer in layers:\n",
    "        rowCharts = []\n",
    "        for head in heads:\n",
    "            rowCharts.append(attn_map(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len))\n",
    "        \n",
    "        charts.append(alt.hconcat(*rowCharts))\n",
    "    return alt.voconcat(*charts)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: In fact, Bazin, curious to know what the mendicant could want with his master, kept pace with him as well as he could, and arrived almost at the same time he did; but his quickness was not of much use to him. At the hint from the mendicant his master made him a sign to retire, and he was obliged to obey.\n",
      "Target: En efecto, Bazin, curioso por saber lo que el mendigo quería de su maestro, había acompasado el paso al suyo, y había llegado casi al mismo tiempo que él; pero esta celeridad no le sirvió de gran cosa; a la invitación del mendigo, su amo le hizo seña de retirarse, y no tuvo más remedio que obedecer.\n"
     ]
    }
   ],
   "source": [
    "batch, encoder_input_tokens, decoder_input_tokens = load_next_batch()\n",
    "print(f'Source: {batch[\"src_text\"][0]}')\n",
    "print(f'Target: {batch[\"tgt_text\"][0]}')\n",
    "\n",
    "# we calculate the lenght4\n",
    "sentence_len = encoder_input_tokens.index('[PAD]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m heads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Encoder Self attenttion\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menocoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 55\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[1;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     53\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[1;32m---> 55\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     57\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvoconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36mattn_map\u001b[1;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[1;32m---> 30\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmtx2df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[0;32m     48\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[22], line 3\u001b[0m, in \u001b[0;36mmtx2df\u001b[1;34m(m, max_row, max_col, row_tokens, col_tokens)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmtx2df\u001b[39m(m, max_row, max_col,row_tokens, col_tokens):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      4\u001b[0m         [\n\u001b[0;32m      5\u001b[0m             (\n\u001b[0;32m      6\u001b[0m                 r,\n\u001b[0;32m      7\u001b[0m                 c,\n\u001b[0;32m      8\u001b[0m                 \u001b[38;5;28mfloat\u001b[39m(m[r,c]),\n\u001b[0;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (r, row_tokens[r] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row_tokens) \u001b[38;5;241m>\u001b[39m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<blank>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (c, col_tokens[c] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(col_tokens) \u001b[38;5;241m>\u001b[39m c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<blank>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m             )\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m<\u001b[39m max_row \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;241m<\u001b[39m max_col\n\u001b[0;32m     16\u001b[0m         ],\n\u001b[0;32m     17\u001b[0m         columns\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_token\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# lets visualize 3 layers of attention\n",
    "layers = [0,1,2]\n",
    "heads = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Encoder Self attenttion\n",
    "get_all_attention_maps(\"enocoder\", layers, heads, encoder_input_tokens, encoder_input_tokens, min(20, sentence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# lets also visualize the attention of the decoder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 55\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[1;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     53\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[1;32m---> 55\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     57\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvoconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m, in \u001b[0;36mattn_map\u001b[1;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[1;32m---> 30\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmtx2df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[0;32m     48\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m, in \u001b[0;36mmtx2df\u001b[1;34m(m, max_row, max_col, row_tokens, col_tokens)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmtx2df\u001b[39m(m, max_row, max_col,row_tokens, col_tokens):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      4\u001b[0m         [\n\u001b[0;32m      5\u001b[0m             (\n\u001b[0;32m      6\u001b[0m                 r,\n\u001b[0;32m      7\u001b[0m                 c,\n\u001b[0;32m      8\u001b[0m                 \u001b[38;5;28mfloat\u001b[39m(m[r,c]),\n\u001b[0;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (r, row_tokens[r] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row_tokens) \u001b[38;5;241m>\u001b[39m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<blank>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (c, col_tokens[c] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(col_tokens) \u001b[38;5;241m>\u001b[39m c \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<blank>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m             )\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m<\u001b[39m max_row \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;241m<\u001b[39m max_col\n\u001b[0;32m     16\u001b[0m         ],\n\u001b[0;32m     17\u001b[0m         columns\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_token\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     18\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# lets also visualize the attention of the decoder\n",
    "get_all_attention_maps(\"decoder\", layers, heads, decoder_input_tokens, decoder_input_tokens, min(20, sentence_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'attn' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_all_attention_maps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menocoder-decoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 55\u001b[0m, in \u001b[0;36mget_all_attention_maps\u001b[1;34m(attn_type, layers, heads, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     53\u001b[0m     rowCharts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m heads:\n\u001b[1;32m---> 55\u001b[0m         rowCharts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sentence_len\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     57\u001b[0m     charts\u001b[38;5;241m.\u001b[39mappend(alt\u001b[38;5;241m.\u001b[39mhconcat(\u001b[38;5;241m*\u001b[39mrowCharts))\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alt\u001b[38;5;241m.\u001b[39mvoconcat(\u001b[38;5;241m*\u001b[39mcharts)\n",
      "Cell \u001b[1;32mIn[17], line 31\u001b[0m, in \u001b[0;36mattn_map\u001b[1;34m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_map\u001b[39m(attn_type, layer, head, row_tokens, col_tokens, max_sentence_len):\n\u001b[0;32m     30\u001b[0m     df \u001b[38;5;241m=\u001b[39m mtx2df(\n\u001b[1;32m---> 31\u001b[0m         \u001b[43mget_attn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     32\u001b[0m         max_sentence_len,\n\u001b[0;32m     33\u001b[0m         max_sentence_len,\n\u001b[0;32m     34\u001b[0m         row_tokens,\n\u001b[0;32m     35\u001b[0m         col_tokens,\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     38\u001b[0m         alt\u001b[38;5;241m.\u001b[39mChart(data\u001b[38;5;241m=\u001b[39mdf)\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;241m.\u001b[39mmark_rect()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;241m.\u001b[39minteractive()\n\u001b[0;32m     48\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[17], line 27\u001b[0m, in \u001b[0;36mget_attn_map\u001b[1;34m(attn_type, layer, head)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder-decoder\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     26\u001b[0m     attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mcross_attention_block\u001b[38;5;241m.\u001b[39mattention_scores\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattn\u001b[49m[\u001b[38;5;241m0\u001b[39m, head]\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'attn' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Cross attention \n",
    "get_all_attention_maps(\"enocoder-decoder\", layers, heads, encoder_input_tokens, decoder_input_tokens, min(20, sentence_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
