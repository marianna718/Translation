For the tokenizer 

we will create a tokenizer to use it on our hugging face dataset
for translation from english to espaniol

bellow see the link of the dataset card in hugging face
our tokenizer will transfer the words of vocabularry into vectors 
and then we will also need to have separate tokens for the begining
and the endingo of the sentance


https://huggingface.co/datasets/Helsinki-NLP/opus_books/viewer/en-es?row=12

